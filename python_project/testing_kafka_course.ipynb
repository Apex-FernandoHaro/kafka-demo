{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis del mercado cripto utilizando Python y Kafka.\n",
    "\n",
    "### Objetivos del Proyecto:\n",
    "\n",
    "A grandes rasgos, el objetivo es replicar un bot de trading, sin la necesidad de que se realicen operaciones en el exchange, y será algo sencillo, ya que no nos interesa tanto el caso de uso, si no que aprendas a manejar kafka con datos en tiempo real y a desacoplar servicios mediante su uso.\n",
    "   \n",
    "La idea es que obtengas datos en tiempo real del mercado, mediante un streaming\n",
    "manejado en kafka, por lo que el proyecto estará dividido en 3 segmentos:\n",
    "   \n",
    "* Funciones Objetivo.\n",
    "* Funciones Extras.\n",
    "* Incorporar Servicios:\n",
    "    - Visualización de Datos.\n",
    "    - Conexión a Base de Datos (este lo dejamos en la primer sección).\n",
    "    - Servicios de ML.\n",
    "    - Data Analytics.\n",
    "    - Reportes.\n",
    "\n",
    "### Instrucciones\n",
    "\n",
    "* Recuerda que lo primero es hacer el fork del repo y posterior a eso crear una carpeta personal en tu repositorio, de esta forma podrás hacer un push a la rama de python, con todo tu código dentro de tu carpeta, nada fuera de ella.\n",
    "\n",
    "###### NO DEBES MODIFICAR NADA EN EL REPO ORIGINAL!!!\n",
    "\n",
    "* Crear las funciones enunciadas en los archivos *producer_functions.py*, *consumer_functions.py* y *project_functions.py* para obtener los puntos asociados a cada uno de ellas.\n",
    "\n",
    "* Utilizar este jupyter notebook para probar tu código. Contiene un ejemplo sencillo de cómo tengo organizado mi script, pero puedes modificarlo como gustes, o incluso borrar todo y empezar de cero. Recuerda que necesitamos este jupyter notebook, ya que tendrá tu desarrollo paso a paso y el cómo pensaste los ejercicios.\n",
    "\n",
    "* Durante el proceso, debes materializar al menos dos tablas en la db, referentes a:\n",
    "    * Datos del Mercado como los recibes.\n",
    "    * Datos generados a partir de tus transformaciones y tu estrategia (si creas alguna). No debes repetir los datos del mercado del punto anterior.\n",
    "\n",
    "* Crear un archivo producer.py que contendrá todo el código necesario para el producer.\n",
    "\n",
    "* Repetir el punto anterior para el consumer.\n",
    "\n",
    "### Consejos y tips.\n",
    "\n",
    "* Recuerda que el objetivo es separar los servicios, por lo que es esperado que trabajes con al menos 2 diferentes archivos, pero puedes trabajar incluso con más de dos archivos, si por ejemplo deseas más organización o si es complicado orgnizar las ideas y las conexiones entre ellas en un solo archivo. A veces ayuda separarlo todo y pensar la lógica de manera granular.\n",
    "\n",
    "* También recuerda que solo los mensajes dentro de una partición están ordenados, NO se ordenan automáticamente si se envían a diferentes particiones, por lo que si haces esto, debes tener una forma de organizarlos y procesarlos posterior a recibirlos en los consumer.\n",
    "\n",
    "* Enfocate en las funciones objetivo, después de ello, pasa a la segunda sección, de esa forma aseguras los puntos fáciles.\n",
    "\n",
    "### TBD\n",
    "\n",
    "Como ya lo mencioné, estamos a contra reloj creando el material para ustedes, por lo que los siguientes puntos están pendientes de entregarles.\n",
    "\n",
    "* Es probable que añada algunas funciones más en las funciones objetivo, estén al pendiente durante el fin de semana.\n",
    "\n",
    "* Las funciones extras: Agregué solo una de momento, pero hace falta agregar más.\n",
    "\n",
    "* Incorporar servicios:\n",
    "    - Alcanza el tiempo?\n",
    "    - Cuáles?\n",
    "\n",
    "* Los puntos asignados a cada función.\n",
    "\n",
    "* Lo más probable es que KSQL no lo alcancemos a ver, pero aún hay esperanza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output # You can use this to clean your output in every loop.\n",
    "from json import loads\n",
    "\n",
    "from datetime import datetime as dt\n",
    "import consumer_functions as cf\n",
    "import project_functions as proj_f\n",
    "\n",
    "### DB Connection Variables.\n",
    "###### Recuerda NO subir tus credenciales a github: siempre puedes crear un JSON, mantener tus credenciales ahí e ingresarlo en tu .gitignore.\n",
    "\n",
    "json_creds = loads('/path/to/json/credentials')\n",
    "user = json_creds['']\n",
    "password = json_creds['']\n",
    "host = json_creds['']\n",
    "db = json_creds['']\n",
    "table_name = 'BTCFDUSD'\n",
    "\n",
    "### Topic name.\n",
    "dw_mk_topic='dw.market.data'\n",
    "\n",
    "# Connection to our database.\n",
    "engine = cf.db_engine(user,password,host,db)\n",
    "\n",
    "# Consumer creation and TopicPartition usage.\n",
    "dw_mk_consumer = cf.consumer(dw_mk_topic)\n",
    "\n",
    "# Loop over the consumer for the latest message they received.\n",
    "for dw_mk_msg in dw_mk_consumer:\n",
    "    \n",
    "    # Cleaning the output on the cells of .ipynb files.\n",
    "    # clear_output(wait=True) \n",
    "    \n",
    "    if dw_mk_msg.value:\n",
    "        # Handling the message value into readable format and creating a dataframe from it.\n",
    "        cf.handling_message(dw_mk_msg)\n",
    "        cf.db_materialization(table_name,engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import producer_functions as prod_f\n",
    "import project_functions as proj_f\n",
    "\n",
    "current_time = dt.now()\n",
    "\n",
    "### get_market_data() & processing_market_data().\n",
    "type_market_data = ''\n",
    "symbol = ''\n",
    "interval = ''\n",
    "rows = ''\n",
    "\n",
    "prod_f.create_producer()\n",
    "\n",
    "i = 0\n",
    "while True:\n",
    "    \n",
    "    ##################################################################################################################################\n",
    "    # Descarga y limpieza de datos de X días atrás a hoy.\n",
    "    ##################################################################################################################################       \n",
    "    recent_data, market_data_msg, received_time = prod_f.processing_market_data(type_market_data,symbol,interval,rows)\n",
    "    \n",
    "    if current_time != recent_data.iloc[-1,0]:\n",
    "        \n",
    "        recent_data = prod_f.transformations(recent_data)\n",
    "        recent_data = proj_f.strategy(recent_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
